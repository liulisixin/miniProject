{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Project: Binary classification with Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your goal is to use your previous experience in order to build a simple binary classifier for Text vs. Non-text classification. Then apply it to classify image patches.\n",
    "\n",
    "The roadmap is as follows:\n",
    "\n",
    "* Load and display images\n",
    "* Import the train/test datasets\n",
    "* Train and Run the Logistic Regression classifier using two different image features:\n",
    " * Raw pixels\n",
    " * Histograms of grey values\n",
    "* Evaluate and compare the classifier results using different evaluation measures\n",
    "* Use your patch classifier in a sliding window scheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary\n",
    "\n",
    "Load images, convert to numpy arrays, reshape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "#Load an image example\n",
    "img = imageio.imread('./img_A.pgm')\n",
    "\n",
    "type(img),img.ndim, img.shape, img.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt #matplotlib plotting library\n",
    "\n",
    "# Display an image\n",
    "plt.imshow(img, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#reshape image array to a vector (1D array)\n",
    "img = np.reshape(img,-1)\n",
    "\n",
    "type(img),img.ndim, img.shape, img.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data acquisition (Optional)\n",
    "\n",
    "This part of the notebook deals with loading images from your hard disk and convert them to NumPy arrays. This is going to be our dataset. Images are stored as pgm files but may be in any other image format. \n",
    "\n",
    "Since we are going to read near 12000 files from disk, it may take around 20 minutes. If you prefer you can jump to the next section of the notebook and load directly the **raw_pixels_dataset_5980.pklz** file, which already contains the NumPy arrays for the entire dataset. The code is here just in case you are curious about how to convert image files into NumPy arrays, and how the **raw_pixels_dataset_5980.pklz** has been created.\n",
    "\n",
    "To execute this part of the notebook you must download the **scene_text_dataset.zip** (<font color='red'>~140 Mb</font>) file from the Campus Virtual site and decompress it in the same directory as this python notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from os import listdir #now we will load all images in a given directory\n",
    "\n",
    "datapath = 'data/characters/icdar/img_ICDAR_train/'\n",
    "\n",
    "char_raw_pixels = np.array([ np.reshape(imageio.imread(datapath+f),-1) for f in listdir(datapath) ])\n",
    "char_raw_pixels = np.reshape(char_raw_pixels,[-1,1024])\n",
    "\n",
    "char_raw_pixels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "datapath = 'data/background/train/'\n",
    "\n",
    "bg_raw_pixels = np.array([ np.reshape(imageio.imread(datapath+f),-1) for f in listdir(datapath) ])\n",
    "bg_raw_pixels = np.reshape(bg_raw_pixels,[-1,1024])\n",
    "\n",
    "bg_raw_pixels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# We want a balanced dataset so we take only the first 5980 background samples\n",
    "bg_raw_pixels = bg_raw_pixels[0:5980,:]\n",
    "bg_raw_pixels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Visualize. Just to be sure the data is correct\n",
    "\n",
    "im = char_raw_pixels[1,:]\n",
    "im = np.reshape(im,[32,32])\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(im, cmap=plt.cm.gray)\n",
    "\n",
    "im = bg_raw_pixels[1,:]\n",
    "im = np.reshape(im,[32,32])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(im, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_features = np.append(char_raw_pixels,bg_raw_pixels, axis=0)\n",
    "\n",
    "char_labels = np.ones([char_raw_pixels.shape[0],1])\n",
    "bg_labels   = np.zeros([bg_raw_pixels.shape[0],1])\n",
    "\n",
    "train_labels = np.append(char_labels, bg_labels)\n",
    "\n",
    "train_features.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#we now do the same for test data\n",
    "\n",
    "datapath = 'data/characters/icdar/img_ICDAR_test/'\n",
    "\n",
    "char_raw_pixels = np.array([ np.reshape(imageio.imread(datapath+f),-1) for f in listdir(datapath) ])\n",
    "char_raw_pixels = np.reshape(char_raw_pixels,[-1,1024])\n",
    "\n",
    "char_raw_pixels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "datapath = 'data/background/test/'\n",
    "\n",
    "bg_raw_pixels = np.array([ np.reshape(imageio.imread(datapath+f),-1) for f in listdir(datapath) ])\n",
    "bg_raw_pixels = np.reshape(bg_raw_pixels,[-1,1024])\n",
    "\n",
    "bg_raw_pixels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "test_features = np.append(char_raw_pixels,bg_raw_pixels, axis=0)\n",
    "\n",
    "char_labels = np.ones([char_raw_pixels.shape[0],1])\n",
    "bg_labels   = np.zeros([bg_raw_pixels.shape[0],1])\n",
    "\n",
    "test_labels = np.append(char_labels, bg_labels)\n",
    "\n",
    "test_features.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Now we can save all our data as python serialized data, so we do not need to read again image\n",
    "# files the next time we want execute our classification code\n",
    "\n",
    "import pickle #module for serialization of python object structure\n",
    "import gzip   #we can compress our data directly when writting data to a file\n",
    "\n",
    "with gzip.open('./raw_pixels_dataset_5980.pklz','wb') as f:\n",
    " pickle.dump((train_labels,train_features,test_labels,test_features),f,pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using raw pixels as features\n",
    "\n",
    "In the following we will try how good are the raw pixel features to automatically classify the different classes.\n",
    "\n",
    "We are going to evaluate classification using Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "with gzip.open('./raw_pixels_dataset_5980.pklz','rb') as f:\n",
    " (train_labels,train_features,test_labels,test_features) = pickle.load(f)\n",
    "\n",
    "print (train_features.shape)\n",
    "print (test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's recover the logistic regression code we have defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(X):\n",
    "    '''\n",
    "    Computes the Sigmoid function of the input argument X.\n",
    "    '''\n",
    "    return 1.0/(1+np.exp(-X))\n",
    "\n",
    "def GradientDescent_logistic_reg(x,y,max_iterations=2500, alpha=0.1, reg_lambda = 1):\n",
    "    \n",
    "    m,n = x.shape # number of samples, number of features\n",
    "\n",
    "    # y must be a column vector\n",
    "    y = y.reshape(m,1)\n",
    "    \n",
    "    #initialize the parameters\n",
    "    theta = np.ones(shape=(n,1)) \n",
    "    \n",
    "    # Repeat until convergence (or max_iterations)\n",
    "    for iteration in range(max_iterations):\n",
    "        h = sigmoid(np.dot(x,theta))\n",
    "        error = (h-y)\n",
    "        gradient = np.dot(x.T , error) / m  + reg_lambda * theta / m   # ADDED THE REGULARISATION TERM\n",
    "        theta = theta - alpha*gradient\n",
    "    return theta\n",
    "\n",
    "def classifyVector(X, theta):\n",
    "    '''\n",
    "    Evaluate the Logistic Regression model h(x) with theta parameters,\n",
    "    and returns the predicted label of x.\n",
    "    '''\n",
    "    prob = sigmoid(sum(np.dot(X,theta)))\n",
    "    if prob > 0.5: return 1.0\n",
    "    else: return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>Use logistic regression to learn a classifier over your training set, using the original pixel data as input</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handcrafted feature extraction\n",
    "\n",
    "We have seen how using the raw pixels is not a good idea. Intuitively there are two main reasons for the bad performance of our classifier: first, we do not have enough data to train in such a high dimensional space (1024-D), second, the raw pixels do not have enough discriminative power to effectively discriminate over the Text and Non-text examples in our dataset. Notice that a simple 1-pixel shift in one of the examples may produce a very different feature vector.\n",
    "\n",
    "In Computer Vision (and in Pattern Recognition in general), feature extraction is a procedure to extract pieces of information which are relevant for solving the computational task at hand. There is a large tradition in designing handcrafted features, that incorporate class prior knowledge, to solve specific problems.\n",
    "\n",
    "In this part of the notebook we are going to extract simple features: histograms of the intensity values of our images. The intuition is that in text image patches we expect to find bi-level histograms (two opposite dominant colors), because text is by design written with high contrast to its background.\n",
    "\n",
    "Then we will evaluate how good those features are for  automatically classifying between the two classes (Text/Non-text) using Logistic Regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#For each example we compute the histogram of grey intensity values\n",
    "\n",
    "new_train_features = np.zeros([train_features.shape[0],8])\n",
    "for i in range(train_features.shape[0]):\n",
    "    new_train_features[i,:] = np.histogram(train_features[i,:],8)[0]\n",
    "    new_train_features[i,:] /= np.sum(new_train_features[i,:]) #Histogram normalization\n",
    "    \n",
    "new_test_features = np.zeros([test_features.shape[0],8])\n",
    "for i in range(test_features.shape[0]):\n",
    "    new_test_features[i,:] = np.histogram(test_features[i,:],8)[0]\n",
    "    new_test_features[i,:] /= np.sum(new_test_features[i,:]) #Histogram normalization\n",
    "    \n",
    "new_train_features.shape, new_test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Visualize the histograms of positive/negative samples\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(np.reshape(train_features[1,:],[32,32]), cmap=plt.cm.gray)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(np.reshape(train_features[5981,:],[32,32]), cmap=plt.cm.gray)\n",
    "\n",
    "bins = [0,1,2,3,4,5,6,7]\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.bar(bins, new_train_features[1,:], align='center')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.bar(bins, new_train_features[5981,:], align='center')\n",
    "\n",
    "#print train_labels[1],train_labels[5981]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>Learn a new classifier using these features</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the use of Histograms of intensity values we have improved the performance of our classifier by more than 20%!\n",
    "\n",
    "Notice that this is a very simple feature extraction process, that is not really used in this way in state-of-the-art algorithms. In fact the proposed features are quite weak (as can be seen with the obtained results). However, the idea here is to take conscience that the design of handcrafted features is a possible way of improving the discrimination power of our classifiers.\n",
    "\n",
    "This experiment also serves to introduce the topic of next Practical (PR2), where we are going to see how it is possible to automatically learn powerful features in an unsupervised way from our training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>Making use the Histogram of intensity values features, evaluate the Precision and Recall measures at different operation points of the classifier. This can be done by changing the 0.5 decision threshold in the ClassifyVector function to a range of values between 0 and 1. Plot the obtained Precision/Recall curve and analyse it.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Sliding Window with our Text vs. Non-text classifier\n",
    "\n",
    "Sliding Window is a common Computer Vision technique used to apply patch-based classifiers into full-size images. The basic idea is to exhaustively evaluate the classifier response in \"all\" possible sub-windows of the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.open(\"img_scene.jpg\")\n",
    "#img.show()\n",
    "\n",
    "img = np.array(img)\n",
    "\n",
    "#pylab.rcParams['figure.figsize'] = 14, 10.5  # changes the default image size for the notebook\n",
    "plt.figure(num=None, figsize=(14, 10.5), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "# Load an image and plot it\n",
    "#img = imageio.imread('img_scene.jpg')\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img, cmap=plt.cm.gray)\n",
    "\n",
    "detection_map = np.zeros(shape=img.shape)\n",
    "\n",
    "win_sizes = (32,64,96)\n",
    "win_step  = 0.2\n",
    "\n",
    "for size in win_sizes:\n",
    "  for x in range(0,img.shape[1]-size,int(size*win_step)):\n",
    "    for y in range(0,img.shape[0]-size,int(size*win_step)):\n",
    "        window = img[y:y+size,x:x+size]\n",
    "        window = np.array(Image.fromarray(window).resize(size = (32,32), resample = Image.BILINEAR))\n",
    "        raw_pixels = np.reshape(window,[-1,1024])\n",
    "        hist_feature = np.histogram(raw_pixels,8)[0]\n",
    "        hist_feature = hist_feature.astype(np.float32)\n",
    "        hist_feature /= np.sum(hist_feature.T)\n",
    "        prob = sigmoid(sum(np.dot(hist_feature,w1)))\n",
    "        detection_map[y:y+size,x:x+size] += 255*prob\n",
    "        \n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(detection_map,cmap=plt.cm.jet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Exercise\n",
    "\n",
    "<font color=blue>Propose and implement an improvement, or an extra evaluation analysis, for our Text vs. Non-text classifier in its current status.</font>\n",
    "\n",
    "Some ideas (not a closed list):\n",
    "\n",
    "* Implement the Stochastic Gradient Descent algorithm. Show how it improves the training time performance.\n",
    "\n",
    "* Use cross-validation to tune the meta-parameters (max_iterations and learning rate $\\alpha$) of Gradient Descent. \n",
    "\n",
    "* Other optimization algorithms?\n",
    "\n",
    "* Evaluate the Test Accuracy as a function of the number of training examples ($m$).\n",
    "\n",
    "* Use Histogram of Oriented Gradients (HOG) image features. http://scikit-image.org/docs/dev/auto_examples/plot_hog.html\n",
    "\n",
    "* Improve the Histogram features. E.g. Evaluate the effect of histogram size. Try different number of bins and compare the obatined results (show precision, recall, accuracy). Can you improve the current Test Accuracy? What is the best accuracy you can reach?\n",
    "\n",
    "* Zoning: compute NxN grey level histograms in a N by N grid of cells over the image patch, and concatenate them to create a new feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
